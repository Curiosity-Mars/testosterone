# Import libraries
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Upload and load dataset
from google.colab import files
uploaded = files.upload()

file_name = list(uploaded.keys())[0]
data = pd.read_csv(file_name)

# Display the first few rows of the dataset
print("Dataset Preview:")
print(data.head())

# Select biomarkers for analysis
X = data[['Creatinine_serum_mg_dL', 'HS C-Reactive Protein (mg/L)', 'Testosterone_total_ng_dL']]
y = data[['Sensitivity', 'Specificity', 'Net_Savings']]

# Handle missing values
X.fillna(X.mean(), inplace=True)
y.fillna(y.mean(), inplace=True)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Build the deep learning model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(32, activation='relu'),
    Dropout(0.3),  # Dropout for regularization
    Dense(3, activation='linear')  # Output: Sensitivity, Specificity, Net Savings
])

# Custom loss function for optimization
def custom_loss(y_true, y_pred):
    sensitivity_loss = -tf.reduce_mean(y_pred[:, 0])  # Maximize sensitivity
    specificity_loss = -tf.reduce_mean(y_pred[:, 1])  # Maximize specificity
    net_savings_loss = -tf.reduce_mean(y_pred[:, 2])  # Maximize cost savings
    return sensitivity_loss + specificity_loss + net_savings_loss

# Compile the model
model.compile(optimizer='adam', loss=custom_loss, metrics=['mse'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Predict on test data
predictions = model.predict(X_test)

# Find optimal thresholds for biomarkers
optimal_index = np.argmax(predictions[:, 2])  # Maximize cost savings
optimal_thresholds = X_test[optimal_index]
optimal_savings = predictions[optimal_index, 2]

# Convert thresholds back to original scale
original_thresholds = scaler.inverse_transform([optimal_thresholds])[0]

# Display results
print(f"Optimal Thresholds (Kidney Function, CRP, Testosterone): {original_thresholds}")
print(f"Maximum Savings: ${optimal_savings:.2f}")

# Cancer patient flag creation for additional analysis
cancer_columns = [col for col in data.columns if col.startswith('MCQ240')]

def is_cancer_patient(row):
    for col in cancer_columns:
        if not pd.isna(row[col]):
            diagnosis_age = row[col]
            if row['Age'] - diagnosis_age <= 5:  # Diagnosed within 5 years
                return 1
    return 0

data['Cancer_Patient'] = data.apply(is_cancer_patient, axis=1)

# Display sample results with cancer patient flags
print(data[['Age'] + cancer_columns + ['Cancer_Patient']].head(10))
